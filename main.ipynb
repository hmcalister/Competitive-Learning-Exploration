{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f46183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, OPTICS\n",
    "from sklearn.metrics import silhouette_score, normalized_mutual_info_score\n",
    "from sklearn.manifold import Isomap, SpectralEmbedding, TSNE, LocallyLinearEmbedding\n",
    "import torch\n",
    "\n",
    "from dataset import AbstractDataset, \\\n",
    "    UniformRandomDataset, \\\n",
    "    PrototypeDataset, \\\n",
    "    MNISTDataset, \\\n",
    "    FashionMNISTDataset\n",
    "\n",
    "from clusterings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7980c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusteringPerformance():\n",
    "    \n",
    "    def __init__(self, dataset: AbstractDataset):\n",
    "        self.dataset = dataset\n",
    "        self.data = {\n",
    "            \"clustering_name\": [],\n",
    "            \"prototype_mean_squared_distance\": [],\n",
    "            \"prototype_std_squared_distance\": [],\n",
    "            \"prototype_mean_min_squared_distance\": [],\n",
    "            \"prototype_std_min_squared_distance\": [],\n",
    "            \"clustering_silhouette\": [],\n",
    "            \"clustering_nmi\": [],\n",
    "        }\n",
    "\n",
    "    def measure_clustering(self, name: str, prototypes: np.ndarray, predicted_labels: np.ndarray):\n",
    "        self.data[\"clustering_name\"].append(name)\n",
    "\n",
    "        squared_distance: np.ndarray = np.square((prototypes[None, :, :] - prototypes[:, None, :])).sum(axis=2)\n",
    "        squared_distance = squared_distance[~np.eye(prototypes.shape[0], dtype=bool)].reshape(prototypes.shape[0], prototypes.shape[0]-1)\n",
    "        self.data[\"prototype_mean_squared_distance\"].append(np.mean(squared_distance))\n",
    "        self.data[\"prototype_std_squared_distance\"].append(np.std(squared_distance))\n",
    "        self.data[\"prototype_mean_min_squared_distance\"].append(np.mean(squared_distance.min(axis=1)))\n",
    "        self.data[\"prototype_std_min_squared_distance\"].append(np.std(squared_distance.min(axis=1)))\n",
    "        \n",
    "        try:\n",
    "            silhouette = silhouette_score(self.dataset.X, predicted_labels)\n",
    "        except ValueError:\n",
    "            silhouette = np.nan\n",
    "        nmi = normalized_mutual_info_score(self.dataset.y, predicted_labels)\n",
    "        self.data[\"clustering_silhouette\"].append(float(silhouette))\n",
    "        self.data[\"clustering_nmi\"].append(float(nmi))\n",
    "\n",
    "    def get_dataframe(self) -> pd.DataFrame:\n",
    "        return pd.DataFrame(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f538e4e6",
   "metadata": {},
   "source": [
    "# Synthetic Prototype Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e981bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POINTS = 1000\n",
    "NUM_FEATURES = 10\n",
    "NUM_DATA_PROTOTYPES = 5\n",
    "INSTANCE_NOISE = 0.4\n",
    "dataset = PrototypeDataset(NUM_DATA_PROTOTYPES,INSTANCE_NOISE,NUM_POINTS,NUM_FEATURES)\n",
    "\n",
    "NUM_CLUSTERING_PROTOTYPES = 20\n",
    "\n",
    "def visualize_prototypes(prototypes: np.ndarray, dataset: AbstractDataset, embedding_method: str = \"TSNE\"):\n",
    "    if NUM_FEATURES < 2:\n",
    "        return\n",
    "    if NUM_FEATURES == 2:\n",
    "        X = dataset.X\n",
    "    if NUM_FEATURES > 2:\n",
    "        match embedding_method:\n",
    "            case \"TSNE\":\n",
    "                embedding = TSNE()\n",
    "            case \"LocallyLinear\":\n",
    "                embedding = LocallyLinearEmbedding()\n",
    "            case \"Isomap\":\n",
    "                embedding = Isomap()\n",
    "            case \"SpectralEmbedding\":\n",
    "                embedding = SpectralEmbedding()\n",
    "            case _:\n",
    "                print(f\"{embedding_method} is not a valid embedding method\")\n",
    "                return\n",
    "        embedded_data = embedding.fit_transform(np.vstack([prototypes, dataset.X]))\n",
    "        prototypes, X = embedded_data[:prototypes.shape[0]], embedded_data[prototypes.shape[0]:]\n",
    "\n",
    "    for prototype_index in range(NUM_DATA_PROTOTYPES):\n",
    "        prototype_mask = dataset.y==prototype_index\n",
    "        plt.scatter(X[prototype_mask, 0], X[prototype_mask, 1], label=f\"{prototype_index}\")\n",
    "    plt.scatter(prototypes[:, 0], prototypes[:, 1], s=10, c=\"k\")\n",
    "    plt.legend(title=\"Prototype Index\")\n",
    "\n",
    "# EMBEDDING_METHODS = [\"TSNE\",\"LocallyLinear\",\"Isomap\",\"SpectralEmbedding\",]\n",
    "EMBEDDING_METHODS = [\"TSNE\"]\n",
    "# EMBEDDING_METHODS = []\n",
    "\n",
    "clustering_performance = ClusteringPerformance(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef5363a",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c9e0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = KMeans(NUM_CLUSTERING_PROTOTYPES)\n",
    "clustering.fit(dataset.X)\n",
    "predicted_labels = clustering.predict(dataset.X)\n",
    "\n",
    "clustering_performance.measure_clustering(\"KMeans\", clustering.cluster_centers_, predicted_labels)\n",
    "for method in EMBEDDING_METHODS:\n",
    "    plt.figure(figsize=(6,6))\n",
    "    visualize_prototypes(clustering.cluster_centers_, dataset, embedding_method=method)\n",
    "    plt.title(f\"Embedding: {method}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ed1ee",
   "metadata": {},
   "source": [
    "### Winner Takes All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d67946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = WinnerTakesAll(NUM_CLUSTERING_PROTOTYPES, NUM_FEATURES)\n",
    "clustering.fit(dataset.X)\n",
    "predicted_labels = clustering.predict(dataset.X)\n",
    "\n",
    "clustering_performance.measure_clustering(\"WinnerTakesAll\", clustering.prototypes, predicted_labels)\n",
    "for method in EMBEDDING_METHODS:\n",
    "    plt.figure(figsize=(6,6))\n",
    "    visualize_prototypes(clustering.prototypes, dataset, embedding_method=method)\n",
    "    plt.title(f\"Embedding: {method}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ab5fe9",
   "metadata": {},
   "source": [
    "### FSCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589bdae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = FSCL(NUM_CLUSTERING_PROTOTYPES, NUM_FEATURES)\n",
    "clustering.fit(dataset.X)\n",
    "predicted_labels = clustering.predict(dataset.X)\n",
    "\n",
    "clustering_performance.measure_clustering(\"FSCL\", clustering.prototypes, predicted_labels)\n",
    "for method in EMBEDDING_METHODS:\n",
    "    plt.figure(figsize=(6,6))\n",
    "    visualize_prototypes(clustering.prototypes, dataset, embedding_method=method)\n",
    "    plt.title(f\"Embedding: {method}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f971ea0f",
   "metadata": {},
   "source": [
    "### RPCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = RPCL(NUM_CLUSTERING_PROTOTYPES, NUM_FEATURES)\n",
    "clustering.fit(dataset.X,best_matching_unit_learning_rate=1e-3,rival_matching_unit_learning_rate=2.75e-4)\n",
    "predicted_labels = clustering.predict(dataset.X)\n",
    "\n",
    "clustering_performance.measure_clustering(\"RPCL\", clustering.prototypes, predicted_labels)\n",
    "for method in EMBEDDING_METHODS:\n",
    "    plt.figure(figsize=(6,6))\n",
    "    visualize_prototypes(clustering.prototypes, dataset, embedding_method=method)\n",
    "    plt.title(f\"Embedding: {method}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4263964e",
   "metadata": {},
   "source": [
    "### Base ClAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87b6f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This specifically will NOT work well with NUM_FEATURES=2 due to the masking of data in ClAM.\n",
    "\n",
    "clustering = ClAMClustering(NUM_CLUSTERING_PROTOTYPES, NUM_FEATURES, beta=1, time_constant=1e0)\n",
    "torchX = torch.tensor(dataset.X)\n",
    "clusteringPerformanceHistoryCallback = ClusteringPerformanceHistoryCallback(clustering, torchX, dataset.y)\n",
    "clustering.add_training_callback(clusteringPerformanceHistoryCallback)\n",
    "prototypeSeparationHistoryCallback = PrototypeSeparationHistoryCallback(clustering)\n",
    "clustering.add_training_callback(prototypeSeparationHistoryCallback)\n",
    "\n",
    "loss = clustering.fit(torchX, num_epochs=1000, batch_size=64, mask_bernoulli_parameter=0.8)\n",
    "# clusteringPerformanceHistory = pd.DataFrame(clusteringPerformanceHistoryCallback.clustering_performance_history)\n",
    "# clusteringPerformanceHistory[\"loss\"] = loss\n",
    "# display(clusteringPerformanceHistory)\n",
    "# for col in clusteringPerformanceHistory:\n",
    "#     y = clusteringPerformanceHistory[col]\n",
    "#     X = np.arange(len(y))\n",
    "#     plt.plot(X, y)\n",
    "#     plt.xlabel(\"Epoch\")\n",
    "#     plt.ylabel(f\"{col}\")\n",
    "#     plt.show()\n",
    "\n",
    "# prototypeSeparationHistory = pd.DataFrame(prototypeSeparationHistoryCallback.prototype_separation_history)\n",
    "# display(prototypeSeparationHistory)\n",
    "# for col in prototypeSeparationHistory:\n",
    "#     y = prototypeSeparationHistory[col]\n",
    "#     X = np.arange(len(y))\n",
    "#     plt.plot(X, y)\n",
    "#     plt.xlabel(\"Epoch\")\n",
    "#     plt.ylabel(f\"{col}\")\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "predicted_labels = clustering.predict(torchX).detach().cpu().numpy()\n",
    "clustering_performance.measure_clustering(\"ClAM\", clustering.prototypes.detach().cpu().numpy(), predicted_labels)\n",
    "for method in EMBEDDING_METHODS:\n",
    "    plt.figure(figsize=(6,6))\n",
    "    visualize_prototypes(clustering.prototypes.detach().cpu().numpy(), dataset, embedding_method=method)\n",
    "    plt.title(f\"Embedding: {method}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c46845",
   "metadata": {},
   "source": [
    "### Regularized ClAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa126dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = RegularizedClAM(\n",
    "    NUM_CLUSTERING_PROTOTYPES, \n",
    "    NUM_FEATURES, \n",
    "    regularization_lambda=1e-4,\n",
    "    regularization_exponent=2,\n",
    "    beta=1, \n",
    "    time_constant=1e0\n",
    ")\n",
    "torchX = torch.tensor(dataset.X)\n",
    "clusteringPerformanceHistoryCallback = ClusteringPerformanceHistoryCallback(clustering, torchX, dataset.y)\n",
    "clustering.add_training_callback(clusteringPerformanceHistoryCallback)\n",
    "prototypeSeparationHistoryCallback = PrototypeSeparationHistoryCallback(clustering)\n",
    "clustering.add_training_callback(prototypeSeparationHistoryCallback)\n",
    "\n",
    "\n",
    "loss = clustering.fit(torchX, num_epochs=1000, batch_size=64, mask_bernoulli_parameter=0.8)\n",
    "# clusteringPerformanceHistory = pd.DataFrame(clusteringPerformanceHistoryCallback.clustering_performance_history)\n",
    "# clusteringPerformanceHistory[\"loss\"] = loss\n",
    "# display(clusteringPerformanceHistory)\n",
    "# for col in clusteringPerformanceHistory:\n",
    "#     y = clusteringPerformanceHistory[col]\n",
    "#     X = np.arange(len(y))\n",
    "#     plt.plot(X, y)\n",
    "#     plt.xlabel(\"Epoch\")\n",
    "#     plt.ylabel(f\"{col}\")\n",
    "#     plt.show()\n",
    "    \n",
    "# prototypeSeparationHistory = pd.DataFrame(prototypeSeparationHistoryCallback.prototype_separation_history)\n",
    "# display(prototypeSeparationHistory)\n",
    "# for col in prototypeSeparationHistory:\n",
    "#     y = prototypeSeparationHistory[col]\n",
    "#     X = np.arange(len(y))\n",
    "#     plt.plot(X, y)\n",
    "#     plt.xlabel(\"Epoch\")\n",
    "#     plt.ylabel(f\"{col}\")\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "predicted_labels = clustering.predict(torchX).detach().cpu().numpy()\n",
    "clustering_performance.measure_clustering(\"L2RegularizedClAM\", clustering.prototypes.detach().cpu().numpy(), predicted_labels)\n",
    "for method in EMBEDDING_METHODS:\n",
    "    plt.figure(figsize=(6,6))\n",
    "    visualize_prototypes(clustering.prototypes.detach().cpu().numpy(), dataset, embedding_method=method)\n",
    "    plt.title(f\"Embedding: {method}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e68fe",
   "metadata": {},
   "source": [
    "### Clustering Performance Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c7558",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clustering_performance.get_dataframe()\n",
    "\n",
    "plt.bar(df[\"clustering_name\"], df[\"prototype_mean_squared_distance\"], yerr=df[\"prototype_std_squared_distance\"])\n",
    "plt.xticks(rotation=25)\n",
    "plt.ylabel(\"Mean Squared Distance between Prototypes\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.bar(df[\"clustering_name\"], df[\"prototype_mean_min_squared_distance\"], yerr=df[\"prototype_std_min_squared_distance\"])\n",
    "plt.xticks(rotation=25)\n",
    "plt.ylabel(\"Mean Squared Minimum Distance between Prototypes\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.bar(df[\"clustering_name\"], df[\"clustering_silhouette\"], label=\"Silhouette Score\")\n",
    "plt.xticks(rotation=25)\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.bar(df[\"clustering_name\"], df[\"clustering_nmi\"], label=\"Normalized Mutual Information\")\n",
    "plt.xticks(rotation=25)\n",
    "plt.ylabel(\"Normalized Mutual Information\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff903a9",
   "metadata": {},
   "source": [
    "# MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f59e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POINTS = 1000\n",
    "dataset = MNISTDataset(NUM_POINTS)\n",
    "# dataset = FashionMNISTDataset(NUM_POINTS)\n",
    "# NUM_DATA_PROTOTYPES = 10\n",
    "NUM_FEATURES = dataset.num_features\n",
    "\n",
    "NUM_CLUSTERING_PROTOTYPES = 20\n",
    "\n",
    "def visualize_MNIST_prototypes(prototypes: np.ndarray, ncols: int = 5, imsize: float=3):\n",
    "    prototypes = prototypes.reshape(-1, 28, 28)\n",
    "    nrows = int(np.ceil(prototypes.shape[0]/ncols))\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*imsize, nrows*imsize))\n",
    "    for i, ax in enumerate(axes.ravel()):\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        if i >= prototypes.shape[0]:\n",
    "            ax.set_frame_on(False)\n",
    "            continue\n",
    "\n",
    "        prototype = prototypes[i, :]\n",
    "        ax.imshow(prototype, cmap=\"grey\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# EMBEDDING_METHODS = [\"TSNE\",\"LocallyLinear\",\"Isomap\",\"SpectralEmbedding\",]\n",
    "EMBEDDING_METHODS = [\"TSNE\"]\n",
    "# EMBEDDING_METHODS = []\n",
    "\n",
    "clustering_performance = ClusteringPerformance(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df2ecb2",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b97da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = KMeans(NUM_CLUSTERING_PROTOTYPES)\n",
    "clustering.fit(dataset.X)\n",
    "predicted_labels = clustering.predict(dataset.X)\n",
    "\n",
    "clustering_performance.measure_clustering(\"KMeans\", clustering.cluster_centers_, predicted_labels)\n",
    "for method in EMBEDDING_METHODS:\n",
    "    visualize_prototypes(clustering.cluster_centers_, dataset, embedding_method=method)\n",
    "    plt.title(f\"Embedding: {method}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8218c230",
   "metadata": {},
   "source": [
    "### Winner Takes All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18fc1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = WinnerTakesAll(NUM_CLUSTERING_PROTOTYPES, NUM_FEATURES)\n",
    "clustering.fit(dataset.X, num_epochs=30)\n",
    "predicted_labels = clustering.predict(dataset.X)\n",
    "\n",
    "clustering_performance.measure_clustering(\"WinnerTakesAll\", clustering.prototypes, predicted_labels)\n",
    "visualize_MNIST_prototypes(clustering.prototypes)\n",
    "for method in EMBEDDING_METHODS:\n",
    "    visualize_prototypes(clustering.prototypes, dataset, embedding_method=method)\n",
    "    plt.title(f\"Embedding: {method}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6d131a",
   "metadata": {},
   "source": [
    "### FSCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d23e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = FSCL(NUM_CLUSTERING_PROTOTYPES, NUM_FEATURES)\n",
    "clustering.fit(dataset.X, num_epochs=30)\n",
    "predicted_labels = clustering.predict(dataset.X)\n",
    "\n",
    "clustering_performance.measure_clustering(\"FSCL\", clustering.prototypes, predicted_labels)\n",
    "visualize_MNIST_prototypes(clustering.prototypes)\n",
    "for method in EMBEDDING_METHODS:\n",
    "    visualize_prototypes(clustering.prototypes, dataset, embedding_method=method)\n",
    "    plt.title(f\"Embedding: {method}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5c855b",
   "metadata": {},
   "source": [
    "### RPCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = RPCL(NUM_CLUSTERING_PROTOTYPES, NUM_FEATURES)\n",
    "clustering.fit(dataset.X, num_epochs=50,best_matching_unit_learning_rate=1e-3,rival_matching_unit_learning_rate=3.5e-4)\n",
    "predicted_labels = clustering.predict(dataset.X)\n",
    "\n",
    "clustering_performance.measure_clustering(\"RPCL\", clustering.prototypes, predicted_labels)\n",
    "visualize_MNIST_prototypes(clustering.prototypes)\n",
    "for method in EMBEDDING_METHODS:\n",
    "    visualize_prototypes(clustering.prototypes, dataset, embedding_method=method)\n",
    "    plt.title(f\"Embedding: {method}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff213b7",
   "metadata": {},
   "source": [
    "### Base ClAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbcbe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = ClAMClustering(NUM_CLUSTERING_PROTOTYPES, NUM_FEATURES, beta=0.1, time_constant=1e0)\n",
    "torchX = torch.tensor(dataset.X)\n",
    "clusteringPerformanceHistoryCallback = ClusteringPerformanceHistoryCallback(clustering, torchX, dataset.y)\n",
    "clustering.add_training_callback(clusteringPerformanceHistoryCallback)\n",
    "prototypeSeparationHistoryCallback = PrototypeSeparationHistoryCallback(clustering)\n",
    "clustering.add_training_callback(prototypeSeparationHistoryCallback)\n",
    "\n",
    "loss = clustering.fit(torchX, num_epochs=1000, batch_size=64, mask_bernoulli_parameter=0.8)\n",
    "# clusteringPerformanceHistory = pd.DataFrame(clusteringPerformanceHistoryCallback.clustering_performance_history)\n",
    "# clusteringPerformanceHistory[\"loss\"] = loss\n",
    "# display(clusteringPerformanceHistory)\n",
    "# for col in clusteringPerformanceHistory:\n",
    "#     y = clusteringPerformanceHistory[col]\n",
    "#     X = np.arange(len(y))\n",
    "#     plt.plot(X, y)\n",
    "#     plt.xlabel(\"Epoch\")\n",
    "#     plt.ylabel(f\"{col}\")\n",
    "#     plt.show()\n",
    "    \n",
    "prototypeSeparationHistory = pd.DataFrame(prototypeSeparationHistoryCallback.prototype_separation_history)\n",
    "display(prototypeSeparationHistory)\n",
    "for col in prototypeSeparationHistory:\n",
    "    y = prototypeSeparationHistory[col]\n",
    "    X = np.arange(len(y))\n",
    "    plt.plot(X, y)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(f\"{col}\")\n",
    "    plt.show()\n",
    "\n",
    "clustering_performance.measure_clustering(\"ClAM\", clustering.prototypes.detach().cpu().numpy(), predicted_labels)\n",
    "visualize_MNIST_prototypes(clustering.prototypes.detach().cpu().numpy())\n",
    "for method in EMBEDDING_METHODS:\n",
    "    visualize_prototypes(clustering.prototypes.detach().cpu().numpy(), dataset, embedding_method=method)\n",
    "    plt.title(f\"Embedding: {method}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b4a390",
   "metadata": {},
   "source": [
    "### Regularized ClAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114fdd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = RegularizedClAM(\n",
    "    NUM_CLUSTERING_PROTOTYPES, \n",
    "    NUM_FEATURES, \n",
    "    regularization_exponent=2,\n",
    "    regularization_lambda=1e-5,\n",
    "    beta=10, \n",
    "    time_constant=1e0\n",
    ")\n",
    "torchX = torch.tensor(dataset.X)\n",
    "clusteringPerformanceHistoryCallback = ClusteringPerformanceHistoryCallback(clustering, torchX, dataset.y)\n",
    "clustering.add_training_callback(clusteringPerformanceHistoryCallback)\n",
    "prototypeSeparationHistoryCallback = PrototypeSeparationHistoryCallback(clustering)\n",
    "clustering.add_training_callback(prototypeSeparationHistoryCallback)\n",
    "\n",
    "loss = clustering.fit(torchX, num_epochs=1000, batch_size=64, mask_bernoulli_parameter=0.8)\n",
    "# clusteringPerformanceHistory = pd.DataFrame(clusteringPerformanceHistoryCallback.clustering_performance_history)\n",
    "# clusteringPerformanceHistory[\"loss\"] = loss\n",
    "# display(clusteringPerformanceHistory)\n",
    "# for col in clusteringPerformanceHistory:\n",
    "#     y = clusteringPerformanceHistory[col]\n",
    "#     X = np.arange(len(y))\n",
    "#     plt.plot(X, y)\n",
    "#     plt.xlabel(\"Epoch\")\n",
    "#     plt.ylabel(f\"{col}\")\n",
    "#     plt.show()\n",
    "    \n",
    "prototypeSeparationHistory = pd.DataFrame(prototypeSeparationHistoryCallback.prototype_separation_history)\n",
    "display(prototypeSeparationHistory)\n",
    "for col in prototypeSeparationHistory:\n",
    "    y = prototypeSeparationHistory[col]\n",
    "    X = np.arange(len(y))\n",
    "    plt.plot(X, y)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(f\"{col}\")\n",
    "    plt.show()\n",
    "\n",
    "clustering_performance.measure_clustering(\"L2RegularizedClAM\", clustering.prototypes.detach().cpu().numpy(), predicted_labels)\n",
    "visualize_MNIST_prototypes(clustering.prototypes.detach().cpu().numpy())\n",
    "for method in EMBEDDING_METHODS:\n",
    "    visualize_prototypes(clustering.prototypes.detach().cpu().numpy(), dataset, embedding_method=method)\n",
    "    plt.title(f\"Embedding: {method}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
